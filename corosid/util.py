import datetime

import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.axes_grid1 import make_axes_locatable

import corosid.batch_linalg as bl


def today():
    return str(datetime.date.today())


def now():
    return datetime.datetime.now().time().strftime('%H-%M-%S')


def create_axis(N, step, centering='pc'):
    """
    Create a one-dimensional coordinate axis with a given size and step size.  Can be such that
    zero is a sample ("pixel-centered", the convention for FFTs), or such that zero is centered
    between two samples ("inter-pixel-centered").

    Parameters
    ----------
    N : int
        Number of pixels in output axis
    step : float
        Physical step size between axis elements
    centering : str
        Either 'pc' (pixel-centered) or 'ipc' (inter-pixel-centered)

    Returns
    -------
    ndarray
        The output coordinate axis
    """
    offset = 0
    if centering == 'ipc':
        offset = 0.5

    axis = (np.arange(N, dtype=np.float64) - N / 2. + offset) * step

    return axis


def broadcast(axis):
    """
    Use numpy array broadcasting to return two views of the input axis that behave like a row
    vector (x) and a column vector (y), and which can be used to build memory-efficient
    coordinate grids without using meshgrid.

    Given an axis with length N, the naive approach using meshgrid requires building two NxN arrays,
    and combining them (e.g. to obtain a radial coordinate grid) produces a third NxN array.
    Using array broadcasting, one only needs to create two separate views into the original Nx1
    vector to create the final NxN array.

    Parameters
    ----------
    axis : np.ndarray
        1D coordinate axis

    Returns
    -------
    tuple of np.ndarray
        Two views into axis that behave like a row and column vector, respectively

    """
    x = axis[None, :]
    y = axis[:, None]
    return x, y


def radial_grid(axis):
    """
    Compute a memory-efficient radial grid using array broadcasting.

    Parameters
    ----------
    axis : np.ndarray
        1D coordinate axis

    Returns
    -------
    np.ndarray
        2D grid with radial coordinates generated by axis
    """
    x, y = broadcast(axis)
    return np.sqrt(x ** 2 + y ** 2)


def l2sqr(x):
    """
    Squared L2 norm. vdot() handles complex numbers correctly whereas dot() and inner() do not.
    """
    return np.vdot(x, x).real


def bin(arr, binfac):
    """
    Bin an array down by integer factor binfac.
    """
    M, N = arr.shape
    new_shape = (M // binfac, binfac, N // binfac, binfac)
    return arr.reshape(new_shape).mean(axis=3).mean(axis=1)


def embed(arr, mask, mask_output=False):
    """
    Embed an array into a higher-dimensional array using a boolean mask.

    Parameters
    ----------
    arr : array_like
    mask : array_like
    mask_output : bool
        Whether to convert the output to a masked array.

    Returns
    -------
    array_like

    """
    output = np.zeros(mask.shape, dtype=arr.dtype)
    output[mask.astype(bool)] = arr

    if mask_output:
        output = np.ma.masked_where(mask == 0, output)

    return output


def compare(val, truth, normalize=True):
    """
    Compute the l2-norm of difference between a value and ground truth. Optionally, normalize this
    value by the norm of the truth value.

    Parameters
    ----------
    val: array_like
    truth: array_like
    normalize: bool, defaults to True

    Returns
    -------
    float

    """
    ret = np.linalg.norm(val - truth)
    if normalize:
        ret /= np.linalg.norm(truth)

    return ret


def rms(arr):
    """
    Compute the root-mean-square value for an array.

    Parameters
    ----------
    arr : np.ndarray
        Input array

    Returns
    -------
    float
    """
    return np.ma.sqrt(np.ma.mean(np.square(arr)))


def normalize_rms(arr, target_rms, mask=None):
    """
    Normalize an array to have a specified root-mean-square (RMS) statistic.

    Parameters
    ----------
    arr : array_like
        Input array
    target_rms : float
        Desired RMS value of the output array
    mask : array_like
        Binary mask indicating the elements of the input array over which to compute the RMS.  All
        elements where the mask has a value of zero are ignored in the input array.  Must have the
        same dimensions as the input.

    Returns
    -------
    array_like
        Input array, scaled so that rms(arr) = target_rms
    """

    if mask is not None:
        actual_rms = rms(np.ma.masked_where(mask, arr, copy=True))
    else:
        actual_rms = rms(arr)

    return arr * target_rms / actual_rms


def add_colorbar(fig, ax, im, label='', size='5%', pad=0.05, visible=True):
    """
    Create a colorbar whose height is matched its plot, with a desired fractional width.

    Parameters
    ----------
    fig : matplotlib.figure.Figure
        Figure handle, i.e. from plt.subplots()
    ax : matplotlib.axes.Axes
        Axis handle, i.e. from plt.subplots()
    im : matplotlib.image.AxesImage
        Image handle, i.e. from ax.imshow()
    label : str
        Label for colorbar
    size : str
        Colorbar width as a percentage of axis width
    pad : float
        Fractional padding between image and colorbar
    visible: bool
        Whether to actually generate and display colorbar after modifying axis to make room for it.
        An example case is when we want multiple adjacent figures to share a colorbar.  All of them
        have to be modified to have room for individual colorbars, but only the last one is
        actually displayed.
    Returns
    -------
    None

    """
    divider = make_axes_locatable(ax)

    cax = divider.append_axes('right', size=size, pad=pad)
    cb = fig.colorbar(im, cax=cax, label=label)

    if not visible:
        cb.remove()

    return cb


def make_H_from_probe_fields(probe_fields):
    L = 2  # Length of state vector: always 2 because state is [real, imag] at each pixel
    num_pix = np.size(probe_fields[0])  # Assumes probe field is already extracted from dark zone
    num_probe_pairs = len(probe_fields)
    H = np.zeros((num_pix, num_probe_pairs, L))

    stacked_fields = np.stack(probe_fields).T
    H[:, :, 0], H[:, :, 1] = np.real(stacked_fields), np.imag(stacked_fields)
    return 4*H


def make_z_from_probe_images(probe_images):
    """ Preprocess raw probe images into data vector """
    num_pix = np.size(probe_images[0])
    num_probe_pairs = len(probe_images) // 2
    z = np.zeros((num_pix, num_probe_pairs))  # Data vector

    for p in range(num_probe_pairs):
        z[:, p] = probe_images[2 * p] - probe_images[2 * p + 1]

    return z


def make_E_from_state(state):
    """ Reshape the per-pixel state vector into a single complex-valued E-field """
    num_pix = state.shape[0]
    E = np.zeros(num_pix, dtype=np.complex128)  # Complex E-field at each pixel

    for n in range(num_pix):
        E[n] = state[n][0] + 1j * state[n][1]

    return E


def make_state_from_field(E_field):
    L = 2  # Length of state vector
    num_pix = np.size(E_field)

    # Gu[k, 0] = Re{control_field[k]}
    # Gu[k, 1] = Im{control_field[k]}
    x = np.zeros((num_pix, L), dtype=np.float64)
    x[:, 0], x[:, 1] = np.real(E_field), np.imag(E_field)

    return x


def l1_pairwise_probe_estimator(H, z):
    """
    "Level 1" pairwise estimator: operates on basic mathematical quantities and computes a state
    vector for each pixel.

    Parameters
    ----------
    H : ndarray
        (num_pix, num_probe_pairs, 2) real-valued observation matrix
    z : ndarray
        (num_pix, num_probe_pairs) data vector: z[n, p] is the difference of probe images from
        probe p at pixel n

    Returns
    -------
    x : ndarray
        (num_pix, 2) state vector: x[n] = [real, imag] part of pixel n
    """
    num_pix, num_probe_pairs, L = H.shape

    x = np.zeros((num_pix, L))  # 2-element state vector [real, imag] for each pixel

    # Estimate state vector for each pixel
    for n in range(num_pix):
        # lstsq returnc (solution, sum of residuals, rank(H), sing. vals. of H).
        # Grab just the solution.
        x[n] = np.linalg.lstsq(H[n], z[n], rcond=None)[0]

    return x


def l2_pairwise_probe_estimator(probe_fields, probe_images):
    """
    "Level 2" pairwise estimator: computes a complex-valued dark-zone E-field given a set of probe
    fields predicted by model, and probe images measured from instrument.

    Parameters
    ----------
    probe_fields: list of ndarray
        List containing the first-order E-fields in the dark zone, contributed by the
        num_probe_pairs probe commands.
    probe_images: list of ndarray
        List containing 2*num_probe_pair arrays. probe_images[2*p] is the image measured when
        probe p is added to the DM commands, while probe_images[2*p+1] is the image measured when
        probe p is subtracted from the current DM commands.

    Returns
    -------
    ndarray
        The complex-valued E-field vector in the dark zone.
    """
    H = make_H_from_probe_fields(probe_fields)
    z = make_z_from_probe_images(probe_images)
    x = l1_pairwise_probe_estimator(H, z)
    return make_E_from_state(x)


def l1_kalman_predict(x, Gu, P, Q):
    # Prediction step
    # - Ordinarily, we would supply the control input u and Jacobian G separately. But algorithmic
    #   differentiation-based algorithms compute the product Gu directly.
    # - These operations can be vectorized over all pixels easily because they're just simple
    #   additions
    return x + Gu, P + Q


def l1_kalman_update(x, z, P, R, H):
    """ Joseph form of Kalman filter update step , which mitigates against roundoff error """
    num_pix, len_z, len_x = H.shape
    I = np.repeat(np.eye(len_x)[np.newaxis], num_pix, axis=0)
    x, P = np.copy(x), np.copy(P)

    v = z - bl.batch_mvip(H, x)
    S = bl.batch_ABAT(H, P) + R
    K = np.einsum('...ij,...kj,...kl->...il', P, H, np.linalg.inv(S))
    x = x + bl.batch_mvip(K, v)
    ikh = I - bl.batch_mmip(K, H)
    P = bl.batch_ABAT(ikh, P) + bl.batch_ABAT(K, R)

    # Equivalent to below (old implementation without vectorization)
    # for n in range(num_pix):
    #     # Update step
    #     v[n] = z[n] - H[n] @ x[n]
    #     S[n] = H[n] @ P[n] @ H[n].T + R[n]
    #     K = P[n] @ H[n].T @ np.linalg.inv(S[n])
    #     x[n] = x[n] + K @ v[n]
    #     ikh = I[n] - K @ H[n]
    #     P[n] = ikh @ P[n] @ ikh.T + K @ R[n] @ K.T
    #
    return x, P, v, S


def l1_rts_smoother(x_posts, x_priors, P_posts, P_priors):
    """
    Rauch-Tung-Striebel smoother. Compute optimal state estimates over a time period consisting of
    K Kalman filter iterations.  This implementation assumes that the state transition matrix is an
    identity matrix (which is the case for coronagraphy- we assuem all state changes are due to
    the DMs).

    Parameters
    ----------
    x_posts : list or array_like
        Posterior state estimates for each Kalman filter iteration. Can be a list of K (num_pix, L)
        arrays or a single (K, num_pix, L) array, where L=2 is the length of the state vector, K is
        the number of iterations, and num_pix is the number of dark-zone pixels.
    x_priors : list or array_like
        Prior state estimates for each Kalman filter iteration. Follows the same shape and
        structure as above.
    P_posts : list or array_like
        Posterior state covariance estimates. Can be a list of K (num_pix, L, L) arrays or a single
        (K, num_pix, L, L) array.
    P_priors : list or array_like
        Prior state covariance estimate, following the same shape and structure as P_posts.

    Returns
    -------
    xs : array_like
        (K, num_pix, L) array of smoothed state estimates.
    Ps : array_like
        (K, num_pix, L, L) array of smoothed state covariance estimates.
    """
    num_pix, L = x_posts[0].shape
    K = len(x_posts)
    xs = np.zeros((K, num_pix, L))
    Ps = np.zeros((K, num_pix, L, L))

    xs[-1] = x_posts[-1]
    Ps[-1] = P_posts[-1]

    for k in range(K-1, 0-1, -1):  # Count down from N-1 to 0, inclusive
        for n in range(num_pix):
            A = P_posts[k][n] @ np.linalg.inv(P_priors[k + 1][n])
            Ps[k][n] = P_posts[k][n] - A @ (P_priors[k + 1][n] - Ps[k + 1][n]) @ A.T
            xs[k][n] = x_posts[k][n] + A @ (xs[k+1][n] - x_priors[k + 1][n])

    return xs, Ps


def bad_to_black(name):
    """ Get a colormap with bad pixels set to black """
    return plt.cm.get_cmap(name).with_extremes(bad='k')


def check_state_transition(estep, dark_zone, k):
    """
    Spot check the state predicted from iteration k-1 against the state estimated in iteration k
    """
    Gu = bl.batch_mvip(estep.G, estep.us[k])
    xm1 = estep.xs[k - 1]  # State estimate in previous iteration
    x_pred = xm1 + Gu      # Predicted state in current iteration
    x = estep.xs[k]        # Actual state estimate in current iteration

    print(100 * compare(Gu, x - xm1))
    print(100 * compare(x_pred, x))

    I_delta = np.abs(make_E_from_state(x) - make_E_from_state(xm1)) ** 2
    I_delta = embed(I_delta, dark_zone, mask_output=True)

    I_Gu = embed(np.abs(make_E_from_state(Gu)) ** 2, dark_zone, mask_output=True)

    fig, axs = plt.subplots(dpi=150, ncols=2, figsize=(10, 4))
    ax = axs[0]
    ax.imshow(I_Gu, cmap=bad_to_black('inferno'), norm=colors.LogNorm(vmin=1e-8, vmax=1e-3))
    # ax.imshow(np.abs(I - coron) / coron,
    #           cmap=bad_to_black('inferno'), norm=colors.Normalize())

    ax = axs[1]
    ax.imshow(I_delta, cmap=bad_to_black('inferno'), norm=colors.LogNorm(vmin=1e-8, vmax=1e-3))

    plt.show()

def check_predicted_intensity(estep: EstimateStates, dark_zone: np.ndarray,
                              target_dir: Path, k: int,
                              wl: int):
    """
    Spot check the predicted dark-zone intensity against the measured image (binned down to the
    same array size)
    """
    I00 = get_I00(target_dir, k, wl)
    E = embed(estep.xs[k][:, 0] + 1j * estep.xs[k][:, 1], dark_zone, mask_output=True)
    I = np.abs(E) ** 2
    coron = np.ma.masked_where(
        dark_zone == 0,
        bin(fits.getdata(target_dir / f'iteration_{k:04d}' / 'coron_640nm.fits') / I00,
                 binfac=3))

    fig, axs = plt.subplots(dpi=150, ncols=2, figsize=(10, 4))
    ax = axs[0]
    ax.imshow(I, cmap=bad_to_black('inferno'), norm=colors.LogNorm(vmin=1e-8, vmax=1e-3))
    # ax.imshow(np.abs(I - coron) / coron,
    #           cmap=bad_to_black('inferno'), norm=colors.Normalize())

    ax = axs[1]
    ax.imshow(coron, cmap=bad_to_black('inferno'), norm=colors.LogNorm(vmin=1e-8, vmax=1e-3))

    print(100 * compare(I[dark_zone], coron[dark_zone]))


def check_predicted_pairwise_data(dark_zone, k, probe_number: int):
    """
    Spot check the predicted probe difference images against the measured ones
    """
    z_pred = bl.batch_mvip(estep.H, estep.xs[k])
    z = estep.zs[k]
    p = probe_number  # Alias this to a mathematical variable

    fig, axs = plt.subplots(dpi=150, ncols=2, figsize=(10, 4))
    ax = axs[0]
    ax.imshow(embed(z_pred[:, p], dark_zone, mask_output=True),
              cmap=bad_to_black('RdBu'), norm=colors.CenteredNorm())

    ax = axs[1]
    ax.imshow(embed(z[:, p], dark_zone, mask_output=True),
              cmap=bad_to_black('RdBu'), norm=colors.CenteredNorm())

    print(100 * compare(z, z_pred))
